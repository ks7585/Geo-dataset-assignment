{
 "cells": [
  
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ks7585/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ks7585/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import bytescale\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.applications import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Given that the image data consists of 13 channels. I used the **gdal** package to open the image data. OpenCV, PIL didn't perform well in exporting the right data. The description also provided details on the Red, Green, Blue (RGB) color channels. I tried to pull in the R,G,B (4,3,2) band data as a numpy array readable by OpenCV. <br>\n",
    "2. Then the 3 data channeled array is merged together to form the RGB image <br> I tried visualizing the different dataset classes. Also, the RGB merged image consists of 16-bit dtype. <br> \n",
    "3. So, every image is converted to 8-bit dtype  with the help of **bytescale** from **scipy.mics**.\n",
    "4. Then i set-up a Loop through all the data folders to perform the same operation and also add the folder name to list everytime an image is read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    ">  ***for every folder (gdal read image --> extract RGB data --> Merge RGB --> convert to 8-bit --> Data.append and Label.append)***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/home/ks7585/one/\"\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "target_height= 224\n",
    "target_width= 224\n",
    "data = []\n",
    "labels = []\n",
    "dataDistributionCounter=0\n",
    "dataDistributionList =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ks7585/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: `bytescale` is deprecated!\n",
      "`bytescale` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Data Folder - 0\n",
      "Current Data Folder - 1\n",
      "Current Data Folder - 2\n",
      "Current Data Folder - 3\n",
      "Current Data Folder - 4\n",
      "Current Data Folder - 5\n",
      "Current Data Folder - 6\n",
      "Current Data Folder - 7\n",
      "Current Data Folder - 8\n",
      "Current Data Folder - 9\n"
     ]
    }
   ],
   "source": [
    "for lab in classes:\n",
    "    for imagePath in glob.glob(path+'/'+str(lab)+'/train_*.tif'):\n",
    "        channels= gdal.Open(imagePath)\n",
    "        R= np.array(channels.GetRasterBand(4).ReadAsArray(),dtype=\"float\") / 255.0 # Getting the Red channel array from the image\n",
    "        G= np.array(channels.GetRasterBand(3).ReadAsArray(),dtype=\"float\") / 255.0 # Getting the Green Channel array from the image\n",
    "        B= np.array(channels.GetRasterBand(2).ReadAsArray(),dtype=\"float\") / 255.0 # Getting the Blue channel array from the image\n",
    "        #print(R.shape,B.shape,G.shape)\n",
    "        img = cv2.merge((B,G,R))                      # Merging 3 channels to make it a RGB image\n",
    "        img = bytescale(img)                          # Scaling the 16-bit image to 8-bit\n",
    "        data.append(cv2.resize(img,(target_width,target_height)))\n",
    "        labels.append(lab)\n",
    "        dataDistributionCounter+=1\n",
    "    dataDistributionList.append(dataDistributionCounter)\n",
    "    dataDistributionCounter = 0\n",
    "    print(\"Data Folder \", lab, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20292, 224, 224, 3)\n",
      "(20292,)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Histogram:\n",
    "Displaying the total number of data available for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb449b54470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(classes,dataDistributionList, color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15219, 224, 224, 3) (5073, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "(trainingImage, validationImage, trainLabel, validationLabel) = train_test_split(data,labels, test_size=0.25, random_state=42)\n",
    "print(trainingImage.shape , validationImage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "trainLabelOneHotEncoded      = to_categorical(trainLabel, num_classes=10)\n",
    "validationLabelOneHotEncoded = to_categorical(validationLabel, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation:\n",
    "With the Bar Chart histogram on top displaying that the number of data available across all the classes is not equal. When having an uneven data, the model tends to lean more towards the class with highest data. In this point of time, collecting more data to equalize the classes isn't a feasible solution. So i performed Data Augmentation here. <br>\n",
    "For Data Augmentation, i performed rotation, width and height shifting, shear intensity, zooming , along with horizontal flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augmentation = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU limiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    " \n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning:\n",
    " Since this is a classification task, i performed transfer learning for the model to learn more from the available data. Keras has many predefined models like vggNet, ResNet, DenseNet, MobileNet. I tried playing around with different models. The data is reshaped according to the input shape of the model. The pretrained **ImageNet** weights are loaded to the model. The previous weights of the model is froze and the model doesn't update those weights. This is done so as to leaverage the learning of the model from the imagenet dataset. \n",
    " <br>\n",
    " The activations of are averaged across each part of the image. Then the model is flattened out. The last fully connected layer is made to produce 10 probability outputs through softmax activation function. <br>\n",
    " Since it is a multiclass classification problem, Categorical crossentropy loss function is used. The learning rate is set to .003. <br>\n",
    " Across playing with different pretrained models, keras has a problem of utilizing most of the GPU and the CPU memory by loading the model and ImageNet weights into memory. VggNet is trained here by passing in the augmented data image and preventing overfitting by adding validation dataset for 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_inception = InceptionV3(weights='imagenet', include_top=False,  input_shape=(299, 299, 3))\n",
    "#res= keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet',input_shape=(224, 224, 3))\n",
    "vgg=keras.applications.vgg19.VGG19(include_top=False, weights='imagenet',input_shape=(target_width, target_height, 3))\n",
    "#mob=keras.applications.mobilenet_v2.MobileNetV2(input_shape=(224, 224, 3),include_top=False, weights='imagenet')\n",
    "out = vgg.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "#total_classes = y_train_ohe.shape[1]\n",
    "predictions = Dense(10, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=vgg.input, outputs=predictions)\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "  \n",
    " \n",
    "model.compile(Adam(lr=.003), loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit_generator(augmentation.flow(trainingImage, trainLabelOneHotEncoded, batch_size=1),\n",
    "                              steps_per_epoch=250,\n",
    "                              validation_data=(validationImage, validationLabelOneHotEncoded),\n",
    "                              validation_steps=250 ,\n",
    "                              epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('karthik.hdf5')\n",
    "\n",
    "print(\"Model Saved \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "t = f.suptitle('Deep Neural Net Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epochs = list(range(1,101))\n",
    "ax1.plot(epochs, history.history['acc'], label='Train Accuracy')\n",
    "ax1.plot(epochs, history.history['val_acc'], label='Validation Accuracy')\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epochs, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epochs, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(epochs)\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing:\n",
    "The saved model is loaded from the disk to predict the test set. The testing set dataset is loaded and preprocessed similar to the training dataset and reshaped to the model input size. Then the model is made to predict on the test dataset. The predictions from the model is arranged in the form of Pandas DataFrame along with the data path. This dataframe is saved to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('karthik.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ks7585/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `bytescale` is deprecated!\n",
      "`bytescale` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "testData = []\n",
    "path= []\n",
    "for imagePath in glob.glob('test_set/test*.tif'):\n",
    "        testChannel= gdal.Open(imagePath)\n",
    "        R= np.array(testChannel.GetRasterBand(4).ReadAsArray(),dtype=\"float\") / 255.0 # Getting the Red channel array from the image\n",
    "        G= np.array(testChannel.GetRasterBand(3).ReadAsArray(),dtype=\"float\") / 255.0 # Getting the Green Channel array from the image\n",
    "        B= np.array(testChannel.GetRasterBand(2).ReadAsArray(),dtype=\"float\") / 255.0 # Getting the Blue channel array from the image\n",
    "        #print(R.shape,B.shape,G.shape)\n",
    "        img = cv2.merge((B,G,R))                      # Merging 3 channels to make it a RGB image\n",
    "        img = bytescale(img)                          # Scaling the 16-bit image to 8-bit\n",
    "        img = cv2.resize(img,(224,224))\n",
    "        #plt.imshow(img)\n",
    "        #image = img_to_array(img)\n",
    "        testData.append (img)\n",
    "        path.append (\"./\"+imagePath)\n",
    "test_data = np.array(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./test_set/test_4311.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./test_set/test_4089.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./test_set/test_1172.tif</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./test_set/test_5447.tif</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./test_set/test_183.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./test_set/test_3433.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./test_set/test_5385.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./test_set/test_5116.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./test_set/test_3135.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./test_set/test_144.tif</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./test_set/test_5738.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./test_set/test_3711.tif</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./test_set/test_3124.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./test_set/test_3939.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./test_set/test_730.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./test_set/test_5479.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./test_set/test_3637.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./test_set/test_2043.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./test_set/test_5959.tif</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./test_set/test_784.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./test_set/test_3431.tif</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./test_set/test_5108.tif</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>./test_set/test_3420.tif</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./test_set/test_32.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>./test_set/test_2289.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./test_set/test_549.tif</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>./test_set/test_4129.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./test_set/test_2554.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>./test_set/test_1267.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./test_set/test_4700.tif</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6678</th>\n",
       "      <td>./test_set/test_5472.tif</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6679</th>\n",
       "      <td>./test_set/test_4531.tif</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>./test_set/test_3618.tif</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6681</th>\n",
       "      <td>./test_set/test_5236.tif</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>./test_set/test_3478.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683</th>\n",
       "      <td>./test_set/test_6094.tif</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6684</th>\n",
       "      <td>./test_set/test_4714.tif</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>./test_set/test_4864.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6686</th>\n",
       "      <td>./test_set/test_6307.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6687</th>\n",
       "      <td>./test_set/test_1476.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>./test_set/test_5229.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>./test_set/test_3590.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6690</th>\n",
       "      <td>./test_set/test_130.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6691</th>\n",
       "      <td>./test_set/test_78.tif</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6692</th>\n",
       "      <td>./test_set/test_2743.tif</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6693</th>\n",
       "      <td>./test_set/test_1826.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6694</th>\n",
       "      <td>./test_set/test_3384.tif</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>./test_set/test_2756.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6696</th>\n",
       "      <td>./test_set/test_523.tif</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6697</th>\n",
       "      <td>./test_set/test_800.tif</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>./test_set/test_5080.tif</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>./test_set/test_2008.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>./test_set/test_5072.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>./test_set/test_319.tif</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>./test_set/test_5816.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>./test_set/test_480.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>./test_set/test_1461.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>./test_set/test_5189.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>./test_set/test_1005.tif</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>./test_set/test_5883.tif</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6708 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      filename  labels\n",
       "0     ./test_set/test_4311.tif       7\n",
       "1     ./test_set/test_4089.tif       2\n",
       "2     ./test_set/test_1172.tif       9\n",
       "3     ./test_set/test_5447.tif       8\n",
       "4      ./test_set/test_183.tif       0\n",
       "5     ./test_set/test_3433.tif       7\n",
       "6     ./test_set/test_5385.tif       7\n",
       "7     ./test_set/test_5116.tif       3\n",
       "8     ./test_set/test_3135.tif       2\n",
       "9      ./test_set/test_144.tif       9\n",
       "10    ./test_set/test_5738.tif       7\n",
       "11    ./test_set/test_3711.tif       5\n",
       "12    ./test_set/test_3124.tif       1\n",
       "13    ./test_set/test_3939.tif       2\n",
       "14     ./test_set/test_730.tif       7\n",
       "15    ./test_set/test_5479.tif       0\n",
       "16    ./test_set/test_3637.tif       2\n",
       "17    ./test_set/test_2043.tif       0\n",
       "18    ./test_set/test_5959.tif       6\n",
       "19     ./test_set/test_784.tif       7\n",
       "20    ./test_set/test_3431.tif       9\n",
       "21    ./test_set/test_5108.tif       6\n",
       "22    ./test_set/test_3420.tif       8\n",
       "23      ./test_set/test_32.tif       7\n",
       "24    ./test_set/test_2289.tif       3\n",
       "25     ./test_set/test_549.tif       4\n",
       "26    ./test_set/test_4129.tif       2\n",
       "27    ./test_set/test_2554.tif       7\n",
       "28    ./test_set/test_1267.tif       1\n",
       "29    ./test_set/test_4700.tif       6\n",
       "...                        ...     ...\n",
       "6678  ./test_set/test_5472.tif       9\n",
       "6679  ./test_set/test_4531.tif       6\n",
       "6680  ./test_set/test_3618.tif       6\n",
       "6681  ./test_set/test_5236.tif       8\n",
       "6682  ./test_set/test_3478.tif       7\n",
       "6683  ./test_set/test_6094.tif       4\n",
       "6684  ./test_set/test_4714.tif       5\n",
       "6685  ./test_set/test_4864.tif       7\n",
       "6686  ./test_set/test_6307.tif       3\n",
       "6687  ./test_set/test_1476.tif       1\n",
       "6688  ./test_set/test_5229.tif       2\n",
       "6689  ./test_set/test_3590.tif       7\n",
       "6690   ./test_set/test_130.tif       1\n",
       "6691    ./test_set/test_78.tif       4\n",
       "6692  ./test_set/test_2743.tif       8\n",
       "6693  ./test_set/test_1826.tif       7\n",
       "6694  ./test_set/test_3384.tif       5\n",
       "6695  ./test_set/test_2756.tif       2\n",
       "6696   ./test_set/test_523.tif       4\n",
       "6697   ./test_set/test_800.tif       8\n",
       "6698  ./test_set/test_5080.tif       5\n",
       "6699  ./test_set/test_2008.tif       3\n",
       "6700  ./test_set/test_5072.tif       2\n",
       "6701   ./test_set/test_319.tif       4\n",
       "6702  ./test_set/test_5816.tif       2\n",
       "6703   ./test_set/test_480.tif       0\n",
       "6704  ./test_set/test_1461.tif       2\n",
       "6705  ./test_set/test_5189.tif       7\n",
       "6706  ./test_set/test_1005.tif       9\n",
       "6707  ./test_set/test_5883.tif       4\n",
       "\n",
       "[6708 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "predictionsTest = pd.DataFrame(predict)\n",
    "predictions = list(predictionsTest.idxmax(axis=1))\n",
    "data_tuples = list(zip(path,predictions))\n",
    "DataFrame=pd.DataFrame(data_tuples, columns=['filename','labels'])\n",
    "DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.to_csv('test_labels.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
